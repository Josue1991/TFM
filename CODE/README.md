# TFM - CÃ³digo Fuente

Estructura del proyecto optimizado para repositorio Git.

## ğŸ“ Estructura

```
CODE/
â”œâ”€â”€ TFM_Fase1/           # CNN con 2 datasets
â”‚   â”œâ”€â”€ cnn_experimento.py
â”‚   â”œâ”€â”€ cnn_modelo.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ TFM_Fase2/           # LSTM con 2 datasets
â”‚   â”œâ”€â”€ fase2_completo.py
â”‚   â”œâ”€â”€ lstm_modelo.py
â”‚   â”œâ”€â”€ ecg_lstm.py
â”‚   â”œâ”€â”€ har_lstm.py
â”‚   â””â”€â”€ requerimientos.txt
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ MEJORAS_APRENDIZAJE.py
â”œâ”€â”€ config/
â”‚   â””â”€â”€ [configuraciÃ³n adicional]
â”œâ”€â”€ requirements.txt     # Dependencias principales
â””â”€â”€ README.md           # Este archivo
```

## ğŸ“‹ Requisitos

```bash
pip install -r requirements.txt
```

O por fase:

**Fase 1 (CNN):**
```bash
cd TFM_Fase1
pip install -r requirements.txt
```

**Fase 2 (LSTM):**
```bash
cd TFM_Fase2
pip install -r requerimientos.txt
```

## ğŸš€ EjecuciÃ³n RÃ¡pida

### Fase 1: CNN (Fashion MNIST + CIFAR-10)

```bash
cd TFM_Fase1
python cnn_experimento.py
```

**Tiempo:**
- CPU: 15-20 minutos (epochs=10)
- GPU: 5-10 minutos (epochs=10)

**ConfiguraciÃ³n:** Editar lÃ­neas 25-26 en `cnn_experimento.py`

```python
EPOCHS_Fashion = 10    # Cambiar aquÃ­
EPOCHS_CIFAR10 = 10    # Cambiar aquÃ­
```

### Fase 2: LSTM (ECG5000 + UCI HAR)

```bash
cd TFM_Fase2
python fase2_completo.py
```

**Tiempo:**
- CPU: 30-40 minutos
- GPU: 10-15 minutos

**ConfiguraciÃ³n:** Editar lÃ­neas 28-30 en `fase2_completo.py`

```python
EPOCHS_ECG = 50      # Cambiar aquÃ­
EPOCHS_HAR = 30      # Cambiar aquÃ­
BATCH_SIZE = 32
```

## âš™ï¸ ConfiguraciÃ³n por Necesidad

### Testing RÃ¡pido (5-10 minutos)
```python
# Fase 1
EPOCHS_Fashion = 2
EPOCHS_CIFAR10 = 2

# Fase 2
EPOCHS_ECG = 2
EPOCHS_HAR = 2
```

### Resultados Buenos (30-60 minutos)
```python
# Fase 1
EPOCHS_Fashion = 10
EPOCHS_CIFAR10 = 10

# Fase 2
EPOCHS_ECG = 20
EPOCHS_HAR = 15
```

### Resultados Ã“ptimos (2-3+ horas)
```python
# Fase 1
EPOCHS_Fashion = 20
EPOCHS_CIFAR10 = 20

# Fase 2
EPOCHS_ECG = 100
EPOCHS_HAR = 80
```

## ğŸ“Š Salidas

Los scripts generan:

**Archivos CSV:**
- `csv_data/resultados_fase1.csv`
- `csv_data/fase2_completo.csv`

**GrÃ¡ficos:**
- `results/grafico_accuracy.png`
- `results/grafico_loss.png`
- `results/grafico_tiempo.png`
- `results/fase2_lstm_training.png`

## ğŸ¯ Optimizaciones Implementadas

### Early Stopping
- **ParÃ¡metro:** patience=15
- **Monitor:** val_loss
- **Efecto:** Evita overfitting automÃ¡ticamente

### Learning Rate Scheduler
- **Tipo:** ReduceLROnPlateau
- **Factor:** 0.5
- **Patience:** 5
- **Efecto:** Ajusta learning rate cuando val_loss se estanca

### RegularizaciÃ³n
- **Batch Normalization:** En cada capa convolucional/LSTM
- **Dropout:** 0.3-0.5 segÃºn la capa
- **L2 Regularization:** 0.001 en todas las capas

### Arquitectura
- **CNN:** Conv2D â†’ BatchNorm â†’ Dropout â†’ MaxPool (3 bloques)
- **LSTM:** Bidirectional LSTM con BatchNorm y Dropout

### Optimizador
- **Adam:** learning_rate=0.001, beta_1=0.9, beta_2=0.999

## ğŸ”§ Troubleshooting

### Memoria insuficiente
```python
# En cnn_experimento.py o fase2_completo.py:
BATCH_SIZE = 16  # Reducir de 32
```

### Quiero solo CPU
```python
DEVICE = 'CPU'  # No usar GPU
```

### GPU no detectada
```bash
# Verificar:
python -c "import tensorflow as tf; print(tf.config.list_physical_devices('GPU'))"
```

## ğŸ“ Estructura de CÃ³digo

### TFM_Fase1/cnn_experimento.py
- Carga datasets (Fashion MNIST + CIFAR-10)
- Preprocesa imÃ¡genes (normalizaciÃ³n, resizing, conversiÃ³n RGB)
- Entrena modelos CNN
- Genera resultados y grÃ¡ficos

### TFM_Fase1/cnn_modelo.py
- `build_cnn_model()`: Construye arquitectura CNN
- `train_and_measure()`: Entrena con optimizaciones
- Early Stopping + ReduceLROnPlateau

### TFM_Fase2/fase2_completo.py
- Carga datasets (ECG5000 + UCI HAR)
- Construye modelos LSTM bidireccionales
- Entrena con validaciÃ³n separada
- Genera grÃ¡ficos de training history

### utils/MEJORAS_APRENDIZAJE.py
- 7 tÃ©cnicas de optimizaciÃ³n documentadas
- Ejemplos de implementaciÃ³n
- ComparaciÃ³n antes/despuÃ©s

## ğŸš€ Git

Para subir a repositorio:

```bash
cd CODE
git init
git add .
git commit -m "TFM - CÃ³digo fuente con optimizaciones"
git remote add origin [tu-repo]
git push -u origin main
```

## ğŸ“š DocumentaciÃ³n

Para guÃ­as de uso, configuraciÃ³n e instalaciÃ³n:
- Ve a la carpeta **DOCS/**
- O lee **DOCS/README.md**

## âœ… VerificaciÃ³n

Para verificar que todo funciona:

```bash
# Test Fase 1 (2-3 minutos)
cd TFM_Fase1
# Edita cnn_experimento.py: EPOCHS_Fashion = 2, EPOCHS_CIFAR10 = 2
python cnn_experimento.py

# Test Fase 2 (3-5 minutos)
cd ../TFM_Fase2
# Edita fase2_completo.py: EPOCHS_ECG = 2, EPOCHS_HAR = 2
python fase2_completo.py
```

## ğŸ’¡ Tips

1. **Usa GPU en Google Colab** para entrenamientos rÃ¡pidos (25-30 min)
2. **Epochs bajos (2-5)** para testing
3. **Epochs normales (10-30)** para resultados
4. **Cambia BATCH_SIZE** si hay memory issues
5. **Early Stopping detiene automÃ¡ticamente** el entrenamiento

## ğŸ“ Soporte

Para preguntas o problemas:
1. Revisa la documentaciÃ³n en **DOCS/**
2. Verifica los requisitos en **requirements.txt**
3. Intenta con epochs bajos para diagnosticar

---

**Ãšltima actualizaciÃ³n:** Noviembre 2025
**VersiÃ³n:** 1.0
